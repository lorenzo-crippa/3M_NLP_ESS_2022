{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial Eight (R): LSTMs and Bi-LSTMs",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzo-crippa/3M_NLP_ESS_2022/blob/main/Tutorial_Eight_(R)_LSTMs_and_Bi_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I83O24uCtuh"
      },
      "source": [
        "# Classification with LSTMs and Bi-LSTMS\n",
        "\n",
        "## Douglas Rice\n",
        "\n",
        "*This tutorial was originally created by Burt Monroe for his prior work with the Essex Summer School. I've updated and modified it.*\n",
        "\n",
        "In this notebook, we'll move beyond the simple feed-forward architectures we have set up in prior neural networks to setting up neural networks that are explicitly trying to learn about *sequences*. We'll look specifically at **L**ong **S**hort-**T**erm **M**emory (LSTM) and **bi**directional LSTM (bi-LSTM)  networks. In terms of building the models in Keras, the modifications will be relatively straightforward updates. Computationally, however, we are adding significant complexity, and the additional complexity means the models will take longer to estimate.\n",
        "\n",
        "\n",
        "#### Setup Instructions:\n",
        "This notebook was designed to run in a clean R runtime within Google Colab. Before running any of the code below, go up to the menu at the top of the window and click \"runtime,\" then, from the dropdown, click \"Disconnect and Delete Runtime\". Then, reconnect. That should get everything set up to run smoothly. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2luVfeeC5sP"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "B20QmKpR8CSm",
        "outputId": "b990fecf-9dd8-499c-8a6f-9abda742dbc9"
      },
      "source": [
        "install.packages(\"keras\") # install R library for keras; this installs dependencies we'll need, including tensorflow\n",
        "\n",
        "library(tensorflow) # load R library for tensorflow\n",
        "library(keras) # load R library for keras\n",
        "\n",
        "tf$constant(\"Hello Tensorflow\") # check that tensorflow is working"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Rcpp’, ‘RcppTOML’, ‘here’, ‘png’, ‘config’, ‘tfautograph’, ‘reticulate’, ‘tensorflow’, ‘tfruns’, ‘zeallot’\n",
            "\n",
            "\n",
            "Loaded Tensorflow version 2.8.2\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tf.Tensor(b'Hello Tensorflow', shape=(), dtype=string)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tfdatasets\")\n",
        "library(tfdatasets)"
      ],
      "metadata": {
        "id": "A88Xn6L04qIO",
        "outputId": "85aefea6-9e93-4fbf-d827-753c3d482c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWslPUBFeaYd"
      },
      "source": [
        "## Load the IMDB data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url <- \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset <- get_file(\n",
        "  \"aclImdb_v1\",\n",
        "  url,\n",
        "  untar = TRUE,\n",
        "  cache_dir = '.',\n",
        "  cache_subdir = ''\n",
        ")"
      ],
      "metadata": {
        "id": "RWUpGSM78tQX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir <- file.path(\"aclImdb\")\n",
        "list.files(dataset_dir)\n"
      ],
      "metadata": {
        "id": "C3pLHRpw8wNa",
        "outputId": "b9bb9106-63e7-4a43-84b2-ee841062cb90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'imdb.vocab'</li><li>'imdbEr.txt'</li><li>'README'</li><li>'test'</li><li>'train'</li></ol>\n"
            ],
            "text/markdown": "1. 'imdb.vocab'\n2. 'imdbEr.txt'\n3. 'README'\n4. 'test'\n5. 'train'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'imdb.vocab'\n\\item 'imdbEr.txt'\n\\item 'README'\n\\item 'test'\n\\item 'train'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] \"imdb.vocab\" \"imdbEr.txt\" \"README\"     \"test\"       \"train\"     "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir <- file.path(dataset_dir, 'train')\n",
        "list.files(train_dir)"
      ],
      "metadata": {
        "id": "clJkbYVr81tY",
        "outputId": "5b5b15de-16cb-4247-b882-8229e1642eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'labeledBow.feat'</li><li>'neg'</li><li>'pos'</li><li>'unsup'</li><li>'unsupBow.feat'</li><li>'urls_neg.txt'</li><li>'urls_pos.txt'</li><li>'urls_unsup.txt'</li></ol>\n"
            ],
            "text/markdown": "1. 'labeledBow.feat'\n2. 'neg'\n3. 'pos'\n4. 'unsup'\n5. 'unsupBow.feat'\n6. 'urls_neg.txt'\n7. 'urls_pos.txt'\n8. 'urls_unsup.txt'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'labeledBow.feat'\n\\item 'neg'\n\\item 'pos'\n\\item 'unsup'\n\\item 'unsupBow.feat'\n\\item 'urls\\_neg.txt'\n\\item 'urls\\_pos.txt'\n\\item 'urls\\_unsup.txt'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] \"labeledBow.feat\" \"neg\"             \"pos\"             \"unsup\"          \n",
              "[5] \"unsupBow.feat\"   \"urls_neg.txt\"    \"urls_pos.txt\"    \"urls_unsup.txt\" "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file <- file.path(train_dir, 'pos/1181_9.txt')\n",
        "readr::read_file(sample_file)"
      ],
      "metadata": {
        "id": "bqk97bMe84DR",
        "outputId": "b698d521-f2d9-4dbd-e6cc-2f61bc717195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we\\'ve loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife\\'s death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth\\'s pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.'"
            ],
            "text/markdown": "'Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we\\'ve loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife\\'s death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth\\'s pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.'",
            "text/latex": "'Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we\\textbackslash{}'ve loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife\\textbackslash{}'s death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth\\textbackslash{}'s pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.'",
            "text/plain": [
              "[1] \"Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dir <- file.path(train_dir, 'unsup')\n",
        "unlink(remove_dir, recursive = TRUE)"
      ],
      "metadata": {
        "id": "GvY-o2U_9Ci7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size <- 512\n",
        "seed <- 1234\n",
        "\n",
        "raw_train_ds <- text_dataset_from_directory(\n",
        "  'aclImdb/train',\n",
        "  batch_size = batch_size,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  seed = seed\n",
        ")"
      ],
      "metadata": {
        "id": "IazXiv-59FOP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_val_ds <- text_dataset_from_directory(\n",
        "  'aclImdb/train',\n",
        "  batch_size = batch_size,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  seed = seed\n",
        ")\n",
        "\n",
        "raw_test_ds <- text_dataset_from_directory(\n",
        "  'aclImdb/test',\n",
        "  batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "aV3lwnVh9OMp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM_-GXWahjsV"
      },
      "source": [
        "## Apply TextVectorization\n",
        "\n",
        "You can send a different tokenizer to the TextVectorization layer -- and the reviews do have some detritus like html tags that probably should be removed -- but we'll just use the default.\n",
        "\n",
        "Now let's set up our vectorize_layer for real. We'll set our maximum vocabulary and our maximum review length."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features <- 10000\n",
        "sequence_length <- 500\n",
        "\n",
        "vectorize_layer <- layer_text_vectorization(\n",
        "  max_tokens = max_features,\n",
        "  output_mode = \"int\",\n",
        "  output_sequence_length = sequence_length\n",
        ")"
      ],
      "metadata": {
        "id": "-Rn24ft75htN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7pKBqBjncV_"
      },
      "source": [
        "We'll call the adapt function to build the vocabulary from the text of the reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text <- raw_train_ds %>%\n",
        "  dataset_map(function(text, label) text)\n",
        "  \n",
        "vectorize_layer %>% adapt(train_text)"
      ],
      "metadata": {
        "id": "3VQGqJsG6NzV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_text <- function(text, label) {\n",
        "  text <- tf$expand_dims(text, -1L)\n",
        "  list(vectorize_layer(text), label)\n",
        "}"
      ],
      "metadata": {
        "id": "7ZDs2wb0-bXV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds <- raw_train_ds %>% dataset_map(vectorize_text)\n",
        "val_ds <- raw_val_ds %>% dataset_map(vectorize_text)\n",
        "test_ds <- raw_test_ds %>% dataset_map(vectorize_text)"
      ],
      "metadata": {
        "id": "yvsPRsua9iPf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names(raw_val_ds)"
      ],
      "metadata": {
        "id": "oc6Rb_QEo5A4",
        "outputId": "58389769-7f25-412c-b143-291b56114ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'apply'</li><li>'as_numpy_iterator'</li><li>'batch'</li><li>'bucket_by_sequence_length'</li><li>'cache'</li><li>'cardinality'</li><li>'choose_from_datasets'</li><li>'class_names'</li><li>'concatenate'</li><li>'element_spec'</li><li>'enumerate'</li><li>'filter'</li><li>'flat_map'</li><li>'from_generator'</li><li>'from_tensor_slices'</li><li>'from_tensors'</li><li>'get_single_element'</li><li>'group_by_window'</li><li>'interleave'</li><li>'list_files'</li><li>'map'</li><li>'options'</li><li>'padded_batch'</li><li>'prefetch'</li><li>'random'</li><li>'range'</li><li>'reduce'</li><li>'rejection_resample'</li><li>'repeat'</li><li>'sample_from_datasets'</li><li>'scan'</li><li>'shard'</li><li>'shuffle'</li><li>'skip'</li><li>'snapshot'</li><li>'take'</li><li>'take_while'</li><li>'unbatch'</li><li>'unique'</li><li>'window'</li><li>'with_options'</li><li>'zip'</li></ol>\n"
            ],
            "text/markdown": "1. 'apply'\n2. 'as_numpy_iterator'\n3. 'batch'\n4. 'bucket_by_sequence_length'\n5. 'cache'\n6. 'cardinality'\n7. 'choose_from_datasets'\n8. 'class_names'\n9. 'concatenate'\n10. 'element_spec'\n11. 'enumerate'\n12. 'filter'\n13. 'flat_map'\n14. 'from_generator'\n15. 'from_tensor_slices'\n16. 'from_tensors'\n17. 'get_single_element'\n18. 'group_by_window'\n19. 'interleave'\n20. 'list_files'\n21. 'map'\n22. 'options'\n23. 'padded_batch'\n24. 'prefetch'\n25. 'random'\n26. 'range'\n27. 'reduce'\n28. 'rejection_resample'\n29. 'repeat'\n30. 'sample_from_datasets'\n31. 'scan'\n32. 'shard'\n33. 'shuffle'\n34. 'skip'\n35. 'snapshot'\n36. 'take'\n37. 'take_while'\n38. 'unbatch'\n39. 'unique'\n40. 'window'\n41. 'with_options'\n42. 'zip'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'apply'\n\\item 'as\\_numpy\\_iterator'\n\\item 'batch'\n\\item 'bucket\\_by\\_sequence\\_length'\n\\item 'cache'\n\\item 'cardinality'\n\\item 'choose\\_from\\_datasets'\n\\item 'class\\_names'\n\\item 'concatenate'\n\\item 'element\\_spec'\n\\item 'enumerate'\n\\item 'filter'\n\\item 'flat\\_map'\n\\item 'from\\_generator'\n\\item 'from\\_tensor\\_slices'\n\\item 'from\\_tensors'\n\\item 'get\\_single\\_element'\n\\item 'group\\_by\\_window'\n\\item 'interleave'\n\\item 'list\\_files'\n\\item 'map'\n\\item 'options'\n\\item 'padded\\_batch'\n\\item 'prefetch'\n\\item 'random'\n\\item 'range'\n\\item 'reduce'\n\\item 'rejection\\_resample'\n\\item 'repeat'\n\\item 'sample\\_from\\_datasets'\n\\item 'scan'\n\\item 'shard'\n\\item 'shuffle'\n\\item 'skip'\n\\item 'snapshot'\n\\item 'take'\n\\item 'take\\_while'\n\\item 'unbatch'\n\\item 'unique'\n\\item 'window'\n\\item 'with\\_options'\n\\item 'zip'\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] \"apply\"                     \"as_numpy_iterator\"        \n",
              " [3] \"batch\"                     \"bucket_by_sequence_length\"\n",
              " [5] \"cache\"                     \"cardinality\"              \n",
              " [7] \"choose_from_datasets\"      \"class_names\"              \n",
              " [9] \"concatenate\"               \"element_spec\"             \n",
              "[11] \"enumerate\"                 \"filter\"                   \n",
              "[13] \"flat_map\"                  \"from_generator\"           \n",
              "[15] \"from_tensor_slices\"        \"from_tensors\"             \n",
              "[17] \"get_single_element\"        \"group_by_window\"          \n",
              "[19] \"interleave\"                \"list_files\"               \n",
              "[21] \"map\"                       \"options\"                  \n",
              "[23] \"padded_batch\"              \"prefetch\"                 \n",
              "[25] \"random\"                    \"range\"                    \n",
              "[27] \"reduce\"                    \"rejection_resample\"       \n",
              "[29] \"repeat\"                    \"sample_from_datasets\"     \n",
              "[31] \"scan\"                      \"shard\"                    \n",
              "[33] \"shuffle\"                   \"skip\"                     \n",
              "[35] \"snapshot\"                  \"take\"                     \n",
              "[37] \"take_while\"                \"unbatch\"                  \n",
              "[39] \"unique\"                    \"window\"                   \n",
              "[41] \"with_options\"              \"zip\"                      "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Considerations"
      ],
      "metadata": {
        "id": "DMgXDVAa-tAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE <- tf$data$AUTOTUNE\n",
        "\n",
        "train_ds <- train_ds %>%\n",
        "  dataset_cache() %>%\n",
        "  dataset_prefetch(buffer_size = AUTOTUNE)\n",
        "val_ds <- val_ds %>%\n",
        "  dataset_cache() %>%\n",
        "  dataset_prefetch(buffer_size = AUTOTUNE)\n",
        "test_ds <- test_ds %>%\n",
        "  dataset_cache() %>%\n",
        "  dataset_prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "8vC3Ni8a-r3d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXH3FCi-0fuO"
      },
      "source": [
        "# Create the Model\n",
        "\n",
        "Building a basic LSTM is very simple in Keras. We just add an LSTM layer to our sequential model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim <- 16 # set 16 dimensions for our model"
      ],
      "metadata": {
        "id": "Si_JRbl34RVH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS3bZPs-gIy3",
        "outputId": "1add98bc-0134-4525-dbfe-40f9d62f286f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model <- keras_model_sequential() %>%\n",
        "  layer_embedding(max_features + 1, # we want to train this embedding layer. \n",
        "                                    # We bring in the 10,000 most frequent words\n",
        "                                    # in the set, +1 allocated for unknown tokens\n",
        "                                    # so, if there's a token that you don't know\n",
        "                                    # you can still include it and train it.\n",
        "                  embedding_dim) %>%\n",
        "  layer_lstm(units = 16) %>%\n",
        "  layer_dense(units = 1, activation = \"sigmoid\")\n",
        "\n",
        "summary(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "________________________________________________________________________________\n",
            " Layer (type)                       Output Shape                    Param #     \n",
            "================================================================================\n",
            " embedding_2 (Embedding)            (None, None, 16)                160016      \n",
            " lstm_2 (LSTM)                      (None, 16)                      2112        \n",
            " dense_2 (Dense)                    (None, 1)                       17          \n",
            "================================================================================\n",
            "Total params: 162,145\n",
            "Trainable params: 162,145\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model %>% compile(\n",
        "  optimizer = 'adam',\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = c('accuracy')\n",
        ")"
      ],
      "metadata": {
        "id": "IPGqn29j-EJN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history <- model %>% fit(\n",
        "  train_ds,\n",
        "  epochs = 25,\n",
        "  validation_data = val_ds,\n",
        "  verbose = 2\n",
        ")"
      ],
      "metadata": {
        "id": "pOUlRapWDNCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history)"
      ],
      "metadata": {
        "id": "OILCTSYmDz7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results <- model %>% evaluate(test_ds, verbose = 2)"
      ],
      "metadata": {
        "id": "sIwYhpd7-JK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "_sQuIeO5-NLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That looks overfit, and like we could probably cut things off much earlier. There's that weird jump around 20 epochs, so let's go after that to about 30. We're not doing as well, but one reason for that might be that we are clipping the reviews at 250 tokens with max_sequence_length above. In doing so, we are probably losing the reviews that end with their rating (and thus increase the accuracy of some of our more naive approaches). Take some time and play around as an exercise with the specifications to see where we might be able to improve."
      ],
      "metadata": {
        "id": "HBFREElOBEUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a basic bi-LSTM model\n",
        "\n",
        "Let's see if a bi-directional LSTM does any better. Notice again that this is very straightforward; everything mimics our code from before but we've wrapped our `layer_lstm` layer with `bidirectional()`."
      ],
      "metadata": {
        "id": "hpxeavRZB2tV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T93462D1fJId"
      },
      "source": [
        "model <- keras_model_sequential() %>%\n",
        "  layer_embedding(max_features + 1, embedding_dim) %>%\n",
        "  bidirectional(layer_lstm(units = 16)) %>%\n",
        "  layer_dense(units = 1, activation = \"sigmoid\")\n",
        "\n",
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model %>% compile(\n",
        "  optimizer = 'adam',\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = c('accuracy')\n",
        ")"
      ],
      "metadata": {
        "id": "LG3r9SzifJId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history <- model %>% fit(\n",
        "  train_ds,\n",
        "  epochs = 25,\n",
        "  validation_data = val_ds,\n",
        "  verbose = 2\n",
        ")"
      ],
      "metadata": {
        "id": "Ve95sKCufJIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history)"
      ],
      "metadata": {
        "id": "8DHXYu4qfJIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results <- model %>% evaluate(test_ds, verbose = 2)"
      ],
      "metadata": {
        "id": "B2nfH0syfJIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "EjHAdtbifJIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uk1aKWAjy-m"
      },
      "source": [
        "## Build a more expressive, deeper bi-LSTM model with dropout.\n",
        "\n",
        "Bi-LSTMs seem to gain power when stacked in multiple layers. Let's do that, make everything bigger, and add some regularization through dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxX635zxjy-m"
      },
      "source": [
        "model <- keras_model_sequential() %>%\n",
        "  layer_embedding(max_features + 1, 64) %>%\n",
        "  layer_dropout(rate = .3) %>%\n",
        "  bidirectional(layer_lstm(units = 32, return_sequences = TRUE)) %>%\n",
        "  layer_dropout(rate = .2) %>%\n",
        "  bidirectional(layer_lstm(units = 16)) %>%\n",
        "  layer_dense(units = 1, activation = \"sigmoid\")\n",
        "\n",
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model %>% compile(\n",
        "  optimizer = 'adam',\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = c('accuracy')\n",
        ")"
      ],
      "metadata": {
        "id": "ESKVdcE0WAjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This one takes 30 to 35 minutes to fit in R. "
      ],
      "metadata": {
        "id": "Alo3zEMQenxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history <- model %>% fit(\n",
        "  train_ds,\n",
        "  epochs = 15,\n",
        "  validation_data = val_ds,\n",
        "  verbose = 2\n",
        ")"
      ],
      "metadata": {
        "id": "IvnIw1m2WAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history)"
      ],
      "metadata": {
        "id": "CwXVBwBIWAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results <- model %>% evaluate(test_ds, verbose = 2)"
      ],
      "metadata": {
        "id": "4UVAEZn1WAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "K8ysvHNfWAjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RYxaOVKjy-n"
      },
      "source": [
        "Coming in at about 80% in the test set, though the better results with the validation set above makes it look like there might be some room for improvement if you play around with the model. \n",
        "\n",
        "It's worth noting, perhaps, that the even bigger, even more expressive model in the Keras documentation (128-dimensional embedding layer, and TWO 64-node BiLSTM layers -- 2.8 million parameters) gets accuracy in the test set of 86.8%. (https://keras.io/examples/nlp/bidirectional_lstm_imdb/)\n",
        "\n",
        "And we did a bit better, 88%, with our basic feedforward network with some dropout."
      ]
    }
  ]
}