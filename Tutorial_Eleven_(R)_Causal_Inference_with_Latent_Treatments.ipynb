{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial Eleven (R): Causal Inference with Latent Treatments",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzo-crippa/3M_NLP_ESS_2022/blob/main/Tutorial_Eleven_(R)_Causal_Inference_with_Latent_Treatments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I83O24uCtuh"
      },
      "source": [
        "# Causal Inference with Latent Treatments\n",
        "\n",
        "## Douglas Rice\n",
        "\n",
        "\n",
        "In this notebook, we'll work with code and data from Fong and Grimmer's (2021) *AJPS* on \"Causal Inference with Latent Treatments.\" Their study laid out an apporach that ``uses machine learning to discover the measured latent treatments.''  The goal is to understand how features of Donald Trump's tweets influenced citizen evaluations of the tweets. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2luVfeeC5sP"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tidytext\")\n",
        "install.packages(\"texteffect\")\n",
        "install.packages(\"textdata\")\n",
        "install.packages(\"car\")\n",
        "install.packages(\"xtable\")\n",
        "\n",
        "library(tidytext)\n",
        "library(texteffect)\n",
        "library(textdata)\n",
        "library(car)\n",
        "library(xtable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k55a9n5CXjhP",
        "outputId": "19ea4cdd-ffdf-4c54-99f1-d601f7b7e201"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Rcpp’, ‘SnowballC’, ‘hunspell’, ‘janeaustenr’, ‘tokenizers’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘numDeriv’, ‘SparseM’, ‘MatrixModels’, ‘sp’, ‘minqa’, ‘nloptr’, ‘RcppEigen’, ‘carData’, ‘abind’, ‘pbkrtest’, ‘quantreg’, ‘maptools’, ‘lme4’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: MASS\n",
            "\n",
            "Loading required package: boot\n",
            "\n",
            "Loading required package: ggplot2\n",
            "\n",
            "Loading required package: carData\n",
            "\n",
            "\n",
            "Attaching package: ‘car’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:boot’:\n",
            "\n",
            "    logit\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "fwZFSSNi6XzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this, we'll use a corpus of Donald Trump's tweets and associated metadata from Fong & Grimmer. The data comes from YouGov's TweetIndex data from February 4, 2017 to October 31, 2017. YouGov presents citizens with tweets from the then-president and asked them to rate the tweet on a five point scale from from ``Great'' to ``Terrible''. I've posted the dataset on my Google Drive and you access it as follows. "
      ],
      "metadata": {
        "id": "Uzs3a5Q-6Xv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system(\"gdown --id 1EgTgqn3o6edyCH9TUxzErw5iFdTPGHdb\")\n",
        "dat <- read.csv(\"trumpdt.csv\")"
      ],
      "metadata": {
        "id": "cqpFtwirZNPY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(dat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "dTi8AK5YAans",
        "outputId": "0b64d59f-67da-4100-e614-66ec9e07fa84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 304</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>score</th><th scope=col>Gind</th><th scope=col>Gdem</th><th scope=col>Grep</th><th scope=col>saved</th><th scope=col>votes</th><th scope=col>companies</th><th scope=col>heading</th><th scope=col>enjoy</th><th scope=col>leaders</th><th scope=col>⋯</th><th scope=col>statement</th><th scope=col>washington</th><th scope=col>biggest</th><th scope=col>north</th><th scope=col>signed</th><th scope=col>record</th><th scope=col>stories</th><th scope=col>problem</th><th scope=col>chance</th><th scope=col>repeal</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>   0.04735535</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td> -77.82785352</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>  85.10157541</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> -31.27180013</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>-129.17740290</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>  78.85985452</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 304\n\n| <!--/--> | score &lt;dbl&gt; | Gind &lt;int&gt; | Gdem &lt;int&gt; | Grep &lt;int&gt; | saved &lt;int&gt; | votes &lt;int&gt; | companies &lt;int&gt; | heading &lt;int&gt; | enjoy &lt;int&gt; | leaders &lt;int&gt; | ⋯ ⋯ | statement &lt;int&gt; | washington &lt;int&gt; | biggest &lt;int&gt; | north &lt;int&gt; | signed &lt;int&gt; | record &lt;int&gt; | stories &lt;int&gt; | problem &lt;int&gt; | chance &lt;int&gt; | repeal &lt;int&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 |    0.04735535 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 2 |  -77.82785352 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 3 |   85.10157541 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 4 |  -31.27180013 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 5 | -129.17740290 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 6 |   78.85985452 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n\n",
            "text/latex": "A data.frame: 6 × 304\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & score & Gind & Gdem & Grep & saved & votes & companies & heading & enjoy & leaders & ⋯ & statement & washington & biggest & north & signed & record & stories & problem & chance & repeal\\\\\n  & <dbl> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ⋯ & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n\\hline\n\t1 &    0.04735535 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t2 &  -77.82785352 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t3 &   85.10157541 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t4 &  -31.27180013 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t5 & -129.17740290 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t6 &   78.85985452 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  score         Gind Gdem Grep saved votes companies heading enjoy leaders ⋯\n",
              "1    0.04735535 1    0    0    0     0     0         0       0     0       ⋯\n",
              "2  -77.82785352 0    1    0    0     0     0         0       0     0       ⋯\n",
              "3   85.10157541 0    0    1    0     0     0         0       0     0       ⋯\n",
              "4  -31.27180013 1    0    0    0     0     0         0       0     0       ⋯\n",
              "5 -129.17740290 0    1    0    0     0     0         0       0     0       ⋯\n",
              "6   78.85985452 0    0    1    0     0     0         0       0     0       ⋯\n",
              "  statement washington biggest north signed record stories problem chance\n",
              "1 0         0          0       0     0      0      0       0       0     \n",
              "2 0         0          0       0     0      0      0       0       0     \n",
              "3 0         0          0       0     0      0      0       0       0     \n",
              "4 0         0          0       0     0      0      0       0       0     \n",
              "5 0         0          0       0     0      0      0       0       0     \n",
              "6 0         0          0       0     0      0      0       0       0     \n",
              "  repeal\n",
              "1 0     \n",
              "2 0     \n",
              "3 0     \n",
              "4 0     \n",
              "5 0     \n",
              "6 0     "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim(dat) # 4509 tweets, 300 words (4 variables refer to something else)"
      ],
      "metadata": {
        "id": "DddyH-dQOppH",
        "outputId": "b2ece669-9cc0-41c1-ab5a-bc764f29d812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4509</li><li>304</li></ol>\n"
            ],
            "text/markdown": "1. 4509\n2. 304\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 4509\n\\item 304\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 4509  304"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the Data Up"
      ],
      "metadata": {
        "id": "efO76byuA9zq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWslPUBFeaYd"
      },
      "source": [
        "We begin by dividing the data into the rating (Y), a field that features the party ID indicator for the survey respondents evaluation (G), and a data frame of word counts (X). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnG_GeAUdXQ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "15e7077c-034a-42c7-ade8-c64ac6ca983e"
      },
      "source": [
        "Y <- dat[,1]\n",
        "G <- dat[,2:4]\n",
        "X <- dat[,5:ncol(dat)]\n",
        "\n",
        "# take a peak at the set up of the tweets\n",
        "head(X)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 300</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>saved</th><th scope=col>votes</th><th scope=col>companies</th><th scope=col>heading</th><th scope=col>enjoy</th><th scope=col>leaders</th><th scope=col>governor</th><th scope=col>men</th><th scope=col>china</th><th scope=col>luther</th><th scope=col>⋯</th><th scope=col>statement</th><th scope=col>washington</th><th scope=col>biggest</th><th scope=col>north</th><th scope=col>signed</th><th scope=col>record</th><th scope=col>stories</th><th scope=col>problem</th><th scope=col>chance</th><th scope=col>repeal</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 300\n\n| <!--/--> | saved &lt;int&gt; | votes &lt;int&gt; | companies &lt;int&gt; | heading &lt;int&gt; | enjoy &lt;int&gt; | leaders &lt;int&gt; | governor &lt;int&gt; | men &lt;int&gt; | china &lt;int&gt; | luther &lt;int&gt; | ⋯ ⋯ | statement &lt;int&gt; | washington &lt;int&gt; | biggest &lt;int&gt; | north &lt;int&gt; | signed &lt;int&gt; | record &lt;int&gt; | stories &lt;int&gt; | problem &lt;int&gt; | chance &lt;int&gt; | repeal &lt;int&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 4 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 6 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n\n",
            "text/latex": "A data.frame: 6 × 300\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & saved & votes & companies & heading & enjoy & leaders & governor & men & china & luther & ⋯ & statement & washington & biggest & north & signed & record & stories & problem & chance & repeal\\\\\n  & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ⋯ & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n\\hline\n\t1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t3 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t6 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  saved votes companies heading enjoy leaders governor men china luther ⋯\n",
              "1 0     0     0         0       0     0       0        0   0     0      ⋯\n",
              "2 0     0     0         0       0     0       0        0   0     0      ⋯\n",
              "3 0     0     0         0       0     0       0        0   0     0      ⋯\n",
              "4 0     0     0         0       0     0       0        0   0     0      ⋯\n",
              "5 0     0     0         0       0     0       0        0   0     0      ⋯\n",
              "6 0     0     0         0       0     0       0        0   0     0      ⋯\n",
              "  statement washington biggest north signed record stories problem chance\n",
              "1 0         0          0       0     0      0      0       0       0     \n",
              "2 0         0          0       0     0      0      0       0       0     \n",
              "3 0         0          0       0     0      0      0       0       0     \n",
              "4 0         0          0       0     0      0      0       0       0     \n",
              "5 0         0          0       0     0      0      0       0       0     \n",
              "6 0         0          0       0     0      0      0       0       0     \n",
              "  repeal\n",
              "1 0     \n",
              "2 0     \n",
              "3 0     \n",
              "4 0     \n",
              "5 0     \n",
              "6 0     "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many mentions of companies?\n",
        "sum(X$companies) # 51 mentions of companies"
      ],
      "metadata": {
        "id": "KPifqgFoOltr",
        "outputId": "fea36c60-9cb5-4b4f-9327-02f1b6c0bb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "51"
            ],
            "text/markdown": "51",
            "text/latex": "51",
            "text/plain": [
              "[1] 51"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many tweets mention companies?\n",
        "sum(X$companies > 0) # 51 tweets"
      ],
      "metadata": {
        "id": "xGiGCK0wO8Lv",
        "outputId": "33f1bbb1-0416-4645-cfa9-d9fcb8f7dba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "51"
            ],
            "text/markdown": "51",
            "text/latex": "51",
            "text/plain": [
              "[1] 51"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(X$companies) # 1, indeed"
      ],
      "metadata": {
        "id": "CjMmIgycPH4T",
        "outputId": "51f6b313-162a-49fe-8efc-8e75060e9ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1"
            ],
            "text/markdown": "1",
            "text/latex": "1",
            "text/plain": [
              "[1] 1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create training and test sets. The reason to do so here follows from earlier work by Fong & Grimmer (2016); the underlying idea is that by creating a ``training'' and ``test'' set we can separate the process of estimating treatment from the process of estimating effects, and thereby avoid cross-contamination in our causal framework.\n",
        "\n",
        "One challenge here is that our analysis is at the tweet-respondent level; the same tweets are often presented to  Republican, Democrat, and Independent survey respondents. We'd like to ensure that we maintain the tweet groupings across the training and test sets. Therefore, random assignment to the training and test set happens at the tweet level, rather than at the individual level.\n"
      ],
      "metadata": {
        "id": "JlucJMbxwxOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nrow(X)/3 # 1503 tweets"
      ],
      "metadata": {
        "id": "6R1oSXNgPgcg",
        "outputId": "59cc61b3-edd6-43d1-8880-3396614a6f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1503"
            ],
            "text/markdown": "1503",
            "text/latex": "1503",
            "text/plain": [
              "[1] 1503"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrow(X)/3*.5 # 751.5 sampled"
      ],
      "metadata": {
        "id": "QkLS4OCLPjxd",
        "outputId": "c8096c14-edfa-4844-9e42-367147db39ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "751.5"
            ],
            "text/markdown": "751.5",
            "text/latex": "751.5",
            "text/plain": [
              "[1] 751.5"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.tweets <- sample(1:(nrow(X)/3), nrow(X)/3*.5)\n",
        "head(training.tweets)"
      ],
      "metadata": {
        "id": "zMpx8686wd6T",
        "outputId": "0291609d-c5a6-465e-c18c-c1aa1a229182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>474</li><li>650</li><li>836</li><li>397</li><li>1169</li><li>633</li></ol>\n"
            ],
            "text/markdown": "1. 474\n2. 650\n3. 836\n4. 397\n5. 1169\n6. 633\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 474\n\\item 650\n\\item 836\n\\item 397\n\\item 1169\n\\item 633\n\\end{enumerate*}\n",
            "text/plain": [
              "[1]  474  650  836  397 1169  633"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.ind <- c()\n",
        "for (i in 1:length(training.tweets)){\n",
        "  train.ind <- c(train.ind, 3*(training.tweets[i]-1)+(1:3))\n",
        "}"
      ],
      "metadata": {
        "id": "ByWyM5cePp5m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Search\n",
        "\n",
        "Fong and Grimmer develop the supervised Indian Buffet Process for *discovering* latent treatments from text. As background, the Indian Buffet Process is one of many different unsupervised approaches for recovering the latent structure responsible for generating observed data (think LDA and other topic model type processes). The primary advantage of the Indian Buffet Process here is that it produces a binary topic vector, which makes inferring treatment more straightforward than continuous measures. The **supervised** Indian Buffet Process developed by Fong and Grimmer goes a step further by incorporating in the estimation of the latent features both the text of the tweets (X) *and* the response (Y).  \n",
        "\n",
        "As noted above, we separate out the data into training and test sets. We begin then by training the sIBP on the training data. We run the the sIBP across different parameters, allowing us to search for a specification that best reflects the data. \n",
        "\n",
        "This takes about 8 minutes to run. "
      ],
      "metadata": {
        "id": "862c61EU6vJq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cs5TG5eeIcz",
        "outputId": "496942a1-2e3f-45cc-827f-46a017d21641"
      },
      "source": [
        "sibp.search <- sibp_param_search(X, Y, K = 5, alphas = c(3,4), sigmasq.ns = c(0.5, 1), \n",
        "                                 iters = 5, train.ind = train.ind, G = G, seed = 12082017)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 3\n",
            "[1] 0.5\n",
            "[1] 1\n",
            "[1] 4\n",
            "[1] 0.5\n",
            "[1] 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select a Set"
      ],
      "metadata": {
        "id": "2c2UywmDA8ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to select one of these as the set to analyze. We should select the set *before* doing any of the subsequent analysis. We'll follow Fong & Grimmer, and work with the following set. "
      ],
      "metadata": {
        "id": "V6mwGycjXAPk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKbgfjKQeVh8"
      },
      "source": [
        "sibp.fit <- sibp.search[[\"3\"]][[\"0.5\"]][[1]]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see some more details about the set using the top words functionality as below. This is also helpful if you were interested in poking around with different models. **The most important note here is that you should not proceed to inference until you are comfortable with the model you have selected.**"
      ],
      "metadata": {
        "id": "fQ7bsMUDXP-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtable(sibp_top_words(sibp.fit, colnames(X), verbose = TRUE))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "lVC_QaDpXTBC",
        "outputId": "aba36a70-4e28-4490-badb-95c6821635f8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Frequency of treatments: \"\n",
            "[1] 354.1390 200.1528 266.0172 173.9976 113.9997\n",
            "[1] \"Relation between top words and treatments\"\n",
            "          [,1]     [,2]     [,3]     [,4]     [,5]\n",
            "[1,] 0.9547454 1.228397 1.301900 2.019712 2.029291\n",
            "[2,] 0.9547454 1.170223 1.301900 1.791365 1.972772\n",
            "[3,] 0.7801361 1.165447 1.110547 1.723626 1.903796\n",
            "[4,] 0.7108009 1.120314 1.064215 1.620610 1.858840\n",
            "[5,] 0.6632524 1.105227 1.025672 1.132865 1.701299\n",
            "[6,] 0.6632524 1.103123 0.988239 1.072602 1.671516\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A xtable: 10 × 5</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>1</th><th scope=col>2</th><th scope=col>3</th><th scope=col>4</th><th scope=col>5</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>prime     </td><td>high    </td><td>rico   </td><td>senators  </td><td>flotus </td></tr>\n",
              "\t<tr><td>minister  </td><td>nytimes </td><td>puerto </td><td>repeal    </td><td>cuts   </td></tr>\n",
              "\t<tr><td>melania   </td><td>cnn     </td><td>stock  </td><td>replace   </td><td>luther </td></tr>\n",
              "\t<tr><td>flotus    </td><td>nfl     </td><td>market </td><td>republican</td><td>strange</td></tr>\n",
              "\t<tr><td>rico      </td><td>stock   </td><td>players</td><td>healthcare</td><td>alabama</td></tr>\n",
              "\t<tr><td>puerto    </td><td>luther  </td><td>nfl    </td><td>obamacare </td><td>honored</td></tr>\n",
              "\t<tr><td>nytimes   </td><td>premiums</td><td>anthem </td><td>crooked   </td><td>melania</td></tr>\n",
              "\t<tr><td>united    </td><td>strange </td><td>tax    </td><td>dead      </td><td>reform </td></tr>\n",
              "\t<tr><td>conference</td><td>market  </td><td>flag   </td><td>dems      </td><td>tax    </td></tr>\n",
              "\t<tr><td>president </td><td>anthem  </td><td>reform </td><td>pass      </td><td>crime  </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA xtable: 10 × 5\n\n| 1 &lt;chr&gt; | 2 &lt;chr&gt; | 3 &lt;chr&gt; | 4 &lt;chr&gt; | 5 &lt;chr&gt; |\n|---|---|---|---|---|\n| prime      | high     | rico    | senators   | flotus  |\n| minister   | nytimes  | puerto  | repeal     | cuts    |\n| melania    | cnn      | stock   | replace    | luther  |\n| flotus     | nfl      | market  | republican | strange |\n| rico       | stock    | players | healthcare | alabama |\n| puerto     | luther   | nfl     | obamacare  | honored |\n| nytimes    | premiums | anthem  | crooked    | melania |\n| united     | strange  | tax     | dead       | reform  |\n| conference | market   | flag    | dems       | tax     |\n| president  | anthem   | reform  | pass       | crime   |\n\n",
            "text/latex": "A xtable: 10 × 5\n\\begin{tabular}{lllll}\n 1 & 2 & 3 & 4 & 5\\\\\n <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n\\hline\n\t prime      & high     & rico    & senators   & flotus \\\\\n\t minister   & nytimes  & puerto  & repeal     & cuts   \\\\\n\t melania    & cnn      & stock   & replace    & luther \\\\\n\t flotus     & nfl      & market  & republican & strange\\\\\n\t rico       & stock    & players & healthcare & alabama\\\\\n\t puerto     & luther   & nfl     & obamacare  & honored\\\\\n\t nytimes    & premiums & anthem  & crooked    & melania\\\\\n\t united     & strange  & tax     & dead       & reform \\\\\n\t conference & market   & flag    & dems       & tax    \\\\\n\t president  & anthem   & reform  & pass       & crime  \\\\\n\\end{tabular}\n",
            "text/plain": [
              "   1          2        3       4          5      \n",
              "1  prime      high     rico    senators   flotus \n",
              "2  minister   nytimes  puerto  repeal     cuts   \n",
              "3  melania    cnn      stock   replace    luther \n",
              "4  flotus     nfl      market  republican strange\n",
              "5  rico       stock    players healthcare alabama\n",
              "6  puerto     luther   nfl     obamacare  honored\n",
              "7  nytimes    premiums anthem  crooked    melania\n",
              "8  united     strange  tax     dead       reform \n",
              "9  conference market   flag    dems       tax    \n",
              "10 president  anthem   reform  pass       crime  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "YbdpnZoIXrJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above creates a mapping between texts and latent treatments. Therefore, we turn next to leveraging that mapping to infer values of our latent treatments within the test set. "
      ],
      "metadata": {
        "id": "Cs9VSbcZpAqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.test <- t(apply(X[sibp.fit$test.ind,], 1, function(x) (x - sibp.fit$meanX)/sibp.fit$sdX))\n",
        "nu.test <- infer_Z(sibp.fit, X)\n",
        "Z.train <- matrix(as.numeric(sibp.fit$nu >= 0.5), ncol = 5)\n",
        "Z.test <- matrix(as.numeric(nu.test >= 0.5), ncol = 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "kxGVi0ltBG76"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our mapping, we need to turn back towards the party subsets that we are primarily interested in. Therefore, we create a data frame with respondent party indicators.  "
      ],
      "metadata": {
        "id": "MYcJ1DsbpVCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat2 <- data.frame(Y[sibp.fit$test.ind], G[sibp.fit$test.ind,])\n",
        "colnames(dat2) <- c(\"Y\", \"ind\", \"dem\", \"rep\")"
      ],
      "metadata": {
        "id": "nMVVm3w9BLtx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(dat2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "kjHHwZv05qSX",
        "outputId": "cbc051cc-6da4-45dc-aec4-887ba7526857"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 4</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Y</th><th scope=col>ind</th><th scope=col>dem</th><th scope=col>rep</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>7</th><td> -13.02126</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>-109.62065</td><td>0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>9</th><td> 107.56427</td><td>0</td><td>0</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>  10.10317</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>17</th><td> -17.31307</td><td>0</td><td>1</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>18</th><td> 106.48820</td><td>0</td><td>0</td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 4\n\n| <!--/--> | Y &lt;dbl&gt; | ind &lt;int&gt; | dem &lt;int&gt; | rep &lt;int&gt; |\n|---|---|---|---|---|\n| 7 |  -13.02126 | 1 | 0 | 0 |\n| 8 | -109.62065 | 0 | 1 | 0 |\n| 9 |  107.56427 | 0 | 0 | 1 |\n| 16 |   10.10317 | 1 | 0 | 0 |\n| 17 |  -17.31307 | 0 | 1 | 0 |\n| 18 |  106.48820 | 0 | 0 | 1 |\n\n",
            "text/latex": "A data.frame: 6 × 4\n\\begin{tabular}{r|llll}\n  & Y & ind & dem & rep\\\\\n  & <dbl> & <int> & <int> & <int>\\\\\n\\hline\n\t7 &  -13.02126 & 1 & 0 & 0\\\\\n\t8 & -109.62065 & 0 & 1 & 0\\\\\n\t9 &  107.56427 & 0 & 0 & 1\\\\\n\t16 &   10.10317 & 1 & 0 & 0\\\\\n\t17 &  -17.31307 & 0 & 1 & 0\\\\\n\t18 &  106.48820 & 0 & 0 & 1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   Y          ind dem rep\n",
              "7   -13.02126 1   0   0  \n",
              "8  -109.62065 0   1   0  \n",
              "9   107.56427 0   0   1  \n",
              "16   10.10317 1   0   0  \n",
              "17  -17.31307 0   1   0  \n",
              "18  106.48820 0   0   1  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we add in our estimates for the latent treatments inferred above. "
      ],
      "metadata": {
        "id": "y5PNZ0tD6QEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat2$Z1 <- Z.test[,1]\n",
        "dat2$Z2 <- Z.test[,2]\n",
        "dat2$Z3 <- Z.test[,3]\n",
        "dat2$Z4 <- Z.test[,4]\n",
        "dat2$Z5 <- Z.test[,5]"
      ],
      "metadata": {
        "id": "cwv8man95nmx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(dat2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "qjozKyf_6JZA",
        "outputId": "5e634395-982e-409b-a6dc-bbb11433d5d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 9</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Y</th><th scope=col>ind</th><th scope=col>dem</th><th scope=col>rep</th><th scope=col>Z1</th><th scope=col>Z2</th><th scope=col>Z3</th><th scope=col>Z4</th><th scope=col>Z5</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>7</th><td> -13.02126</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>-109.62065</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>9</th><td> 107.56427</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>  10.10317</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>17</th><td> -17.31307</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>18</th><td> 106.48820</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 9\n\n| <!--/--> | Y &lt;dbl&gt; | ind &lt;int&gt; | dem &lt;int&gt; | rep &lt;int&gt; | Z1 &lt;dbl&gt; | Z2 &lt;dbl&gt; | Z3 &lt;dbl&gt; | Z4 &lt;dbl&gt; | Z5 &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|\n| 7 |  -13.02126 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 8 | -109.62065 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 9 |  107.56427 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n| 16 |   10.10317 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 17 |  -17.31307 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n| 18 |  106.48820 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n\n",
            "text/latex": "A data.frame: 6 × 9\n\\begin{tabular}{r|lllllllll}\n  & Y & ind & dem & rep & Z1 & Z2 & Z3 & Z4 & Z5\\\\\n  & <dbl> & <int> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t7 &  -13.02126 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t8 & -109.62065 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t9 &  107.56427 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n\t16 &   10.10317 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t17 &  -17.31307 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\t18 &  106.48820 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   Y          ind dem rep Z1 Z2 Z3 Z4 Z5\n",
              "7   -13.02126 1   0   0   0  0  0  0  0 \n",
              "8  -109.62065 0   1   0   0  0  0  0  0 \n",
              "9   107.56427 0   0   1   0  0  0  0  0 \n",
              "16   10.10317 1   0   0   0  0  0  0  0 \n",
              "17  -17.31307 0   1   0   0  0  0  0  0 \n",
              "18  106.48820 0   0   1   0  0  0  0  0 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment "
      ],
      "metadata": {
        "id": "lVEFfuIN6bbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fong & Grimmer include in their model  sentiment scores estimated via a dictionary approach (AFINN), with tweets dichotomized into positive or negative.  \n"
      ],
      "metadata": {
        "id": "4ua2-4K0paAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system(\"gdown --id 1EkBHsr1aRltyA0KveZFgrLhiTo7G4OvQ\")\n",
        "afinn <- read.csv(\"afinn.csv\")\n",
        "\n",
        "start<- as.matrix(afinn)\n",
        "use0 <- match(colnames(X), start[,2])\n",
        "use <- use0[which(!is.na(use0))]\n",
        "use_col<- which(is.na(match(colnames(X), start[,2]))==F)\n",
        "sents<- as.matrix(X[sibp.fit$test.ind,use_col])%*%as.numeric(start[use,3])\n",
        "dat2$sents <- I(sents > 0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JhOlDyrOBROd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "Notice what we now have. The `dat2` dataframe features the rating, a set of latent of treatment indicators, the party of the respondent, and the sentiment (positive or negative) of the tweet. Recall that the goal of the exercise was to understand the effect of different features on evaluations of Donald Trump's tweets by party. Therefore, Fong & Grimmer estimate three models (one for each of Democratic, Republican, and Independent respondents). "
      ],
      "metadata": {
        "id": "DJHQ282Jped6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Democrats\n",
        "summary(lm(Y ~ Z1 + Z2 + Z3 + Z4 + Z5, data = dat2, subset = which(dat2$dem == 1)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "z2FZKhwkBTlg",
        "outputId": "c328da76-f102-4164-b3fd-f79e54e6fd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Y ~ Z1 + Z2 + Z3 + Z4 + Z5, data = dat2, subset = which(dat2$dem == \n",
              "    1))\n",
              "\n",
              "Residuals:\n",
              "   Min     1Q Median     3Q    Max \n",
              "-71.58 -35.72  -5.23  30.32 123.94 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)  -81.987      1.704 -48.110  < 2e-16 ***\n",
              "Z1           -27.757      5.593  -4.963 8.59e-07 ***\n",
              "Z2           -12.843      7.470  -1.719    0.086 .  \n",
              "Z3            46.701      6.921   6.748 3.02e-11 ***\n",
              "Z4            -3.102     10.510  -0.295    0.768    \n",
              "Z5           -15.820      9.699  -1.631    0.103    \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 43.03 on 746 degrees of freedom\n",
              "Multiple R-squared:  0.08381,\tAdjusted R-squared:  0.07767 \n",
              "F-statistic: 13.65 on 5 and 746 DF,  p-value: 9.125e-13\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Republicans\n",
        "summary(lm(Y ~ Z1 + Z2 + Z3 + Z4 + Z5, data = dat2, subset = which(dat2$rep == 1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "-5Mhfap77kYZ",
        "outputId": "acab7bc8-b0fe-4cee-cad3-a6bb7b11c93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Y ~ Z1 + Z2 + Z3 + Z4 + Z5, data = dat2, subset = which(dat2$rep == \n",
              "    1))\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-91.376 -16.889  -1.232  17.066  65.116 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)   97.769      1.012  96.642  < 2e-16 ***\n",
              "Z1            -9.047      3.320  -2.725 0.006577 ** \n",
              "Z2            -3.971      4.435  -0.896 0.370802    \n",
              "Z3            15.690      4.109   3.819 0.000145 ***\n",
              "Z4            -3.533      6.239  -0.566 0.571354    \n",
              "Z5            -8.560      5.757  -1.487 0.137514    \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 25.55 on 746 degrees of freedom\n",
              "Multiple R-squared:  0.03007,\tAdjusted R-squared:  0.02357 \n",
              "F-statistic: 4.625 on 5 and 746 DF,  p-value: 0.0003651\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Independents\n",
        "summary(lm(Y ~ Z1 + Z2 + Z3 + Z4 + Z5, data = dat2, subset = which(dat2$ind == 1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "Xg0e1yqQ7yp7",
        "outputId": "62ef590a-bf3c-4805-fafe-0f289d2cbf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Y ~ Z1 + Z2 + Z3 + Z4 + Z5, data = dat2, subset = which(dat2$ind == \n",
              "    1))\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-76.807 -26.367  -3.346  22.566  98.127 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)  -0.05033    1.32820  -0.038   0.9698    \n",
              "Z1          -18.43701    4.35876  -4.230 2.63e-05 ***\n",
              "Z2           -5.82438    5.82207  -1.000   0.3174    \n",
              "Z3           30.07931    5.39429   5.576 3.44e-08 ***\n",
              "Z4           -6.88933    8.19177  -0.841   0.4006    \n",
              "Z5          -15.15926    7.55895  -2.005   0.0453 *  \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 33.54 on 746 degrees of freedom\n",
              "Multiple R-squared:  0.0636,\tAdjusted R-squared:  0.05732 \n",
              "F-statistic: 10.13 on 5 and 746 DF,  p-value: 2.1e-09\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the above a few interesting dynamics. First, Z5 (or the fifth latent treatment) seems to be associated with a significant shift in evaluations only among independents. Second, Z1 and Z3 are consistently across party influencing evaluations, and in directions (though not magnitude) that are consistent across party. "
      ],
      "metadata": {
        "id": "EJ67cr1O7_zG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fong & Grimmer go a step further and estimate the models with a sentiment control. Interestingly, with the sentiment control included, thereby addressing another potentially unobserved confounder. The differences in treatment effects across party narrow."
      ],
      "metadata": {
        "id": "bOodwm1RpmUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(lm(Y ~ Z1 + Z2 + Z3 + Z4 + Z5 + sents, data = dat2, subset = which(dat2$dem == 1)))\n",
        "summary(lm(Y ~ Z1 + Z2 + Z3 + Z4 + Z5 + sents, data = dat2, subset = which(dat2$ind == 1)))\n",
        "summary(lm(Y ~ Z1 + Z2 + Z3 + Z4 + Z5 + sents, data = dat2, subset = which(dat2$rep == 1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MMaKfvFjmJDt",
        "outputId": "81a78242-63d4-47ae-b5a0-8a5e806a7531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Y ~ Z1 + Z2 + Z3 + Z4 + Z5 + sents, data = dat2, \n",
              "    subset = which(dat2$dem == 1))\n",
              "\n",
              "Residuals:\n",
              "   Min     1Q Median     3Q    Max \n",
              "-80.85 -33.05  -7.21  29.19 125.54 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)  -92.783      2.122 -43.728  < 2e-16 ***\n",
              "Z1           -26.826      5.372  -4.994 7.38e-07 ***\n",
              "Z2           -11.148      7.177  -1.553   0.1208    \n",
              "Z3            36.813      6.761   5.445 7.04e-08 ***\n",
              "Z4            -1.274     10.096  -0.126   0.8996    \n",
              "Z5           -18.569      9.320  -1.992   0.0467 *  \n",
              "sentsTRUE     24.651      3.084   7.994 4.99e-15 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 41.33 on 745 degrees of freedom\n",
              "Multiple R-squared:  0.1562,\tAdjusted R-squared:  0.1494 \n",
              "F-statistic: 22.98 on 6 and 745 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Y ~ Z1 + Z2 + Z3 + Z4 + Z5 + sents, data = dat2, \n",
              "    subset = which(dat2$ind == 1))\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-78.027 -24.147  -3.551  22.244  95.741 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)   -8.576      1.652  -5.192 2.69e-07 ***\n",
              "Z1           -17.701      4.182  -4.233 2.60e-05 ***\n",
              "Z2            -4.485      5.587  -0.803   0.4224    \n",
              "Z3            22.270      5.263   4.231 2.61e-05 ***\n",
              "Z4            -5.446      7.860  -0.693   0.4886    \n",
              "Z5           -17.330      7.256  -2.389   0.0172 *  \n",
              "sentsTRUE     19.469      2.401   8.110 2.09e-15 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 32.17 on 745 degrees of freedom\n",
              "Multiple R-squared:  0.1396,\tAdjusted R-squared:  0.1326 \n",
              "F-statistic: 20.14 on 6 and 745 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = Y ~ Z1 + Z2 + Z3 + Z4 + Z5 + sents, data = dat2, \n",
              "    subset = which(dat2$rep == 1))\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-88.691 -15.715  -0.689  15.632  62.896 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)   92.507      1.277  72.437  < 2e-16 ***\n",
              "Z1            -8.594      3.233  -2.658  0.00803 ** \n",
              "Z2            -3.145      4.320  -0.728  0.46683    \n",
              "Z3            10.871      4.069   2.672  0.00771 ** \n",
              "Z4            -2.642      6.077  -0.435  0.66380    \n",
              "Z5            -9.900      5.610  -1.765  0.07802 .  \n",
              "sentsTRUE     12.015      1.856   6.473 1.74e-10 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 24.87 on 745 degrees of freedom\n",
              "Multiple R-squared:  0.08172,\tAdjusted R-squared:  0.07432 \n",
              "F-statistic: 11.05 on 6 and 745 DF,  p-value: 8.018e-12\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}